{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498882f8",
   "metadata": {},
   "source": [
    "The data in the dataset is of different faces. We imported the dataset and then loaded the dataset. We made a variable for the dataset called load_olivetti. The load_olivetti variable contains data, target, and DESCR.\n",
    "data = has information about every pixel for every image, has 400 images\n",
    "image dimensions = 64 x 64\n",
    "4096 pixels per image\n",
    "flatten the image\n",
    "40 people were photographed 10 times each\n",
    "target = number represents the person, and each person has 10 photos (so 10 of their number)\n",
    "DESCR = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728762fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e89460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f194dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_olivetti = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9c3861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[0.30991736, 0.3677686 , 0.41735536, ..., 0.15289256, 0.16115703,\n",
      "        0.1570248 ],\n",
      "       [0.45454547, 0.47107437, 0.5123967 , ..., 0.15289256, 0.15289256,\n",
      "        0.15289256],\n",
      "       [0.3181818 , 0.40082645, 0.49173555, ..., 0.14049587, 0.14876033,\n",
      "        0.15289256],\n",
      "       ...,\n",
      "       [0.5       , 0.53305787, 0.607438  , ..., 0.17768595, 0.14876033,\n",
      "        0.19008264],\n",
      "       [0.21487603, 0.21900827, 0.21900827, ..., 0.57438016, 0.59090906,\n",
      "        0.60330576],\n",
      "       [0.5165289 , 0.46280992, 0.28099173, ..., 0.35950413, 0.3553719 ,\n",
      "        0.38429752]], dtype=float32), 'images': array([[[0.30991736, 0.3677686 , 0.41735536, ..., 0.37190083,\n",
      "         0.3305785 , 0.30578512],\n",
      "        [0.3429752 , 0.40495867, 0.43801653, ..., 0.37190083,\n",
      "         0.338843  , 0.3140496 ],\n",
      "        [0.3429752 , 0.41735536, 0.45041323, ..., 0.38016528,\n",
      "         0.338843  , 0.29752067],\n",
      "        ...,\n",
      "        [0.21487603, 0.20661157, 0.2231405 , ..., 0.15289256,\n",
      "         0.16528925, 0.17355372],\n",
      "        [0.20247933, 0.2107438 , 0.2107438 , ..., 0.14876033,\n",
      "         0.16115703, 0.16528925],\n",
      "        [0.20247933, 0.20661157, 0.20247933, ..., 0.15289256,\n",
      "         0.16115703, 0.1570248 ]],\n",
      "\n",
      "       [[0.45454547, 0.47107437, 0.5123967 , ..., 0.19008264,\n",
      "         0.18595041, 0.18595041],\n",
      "        [0.446281  , 0.48347107, 0.5206612 , ..., 0.21487603,\n",
      "         0.2107438 , 0.2107438 ],\n",
      "        [0.49586776, 0.5165289 , 0.53305787, ..., 0.20247933,\n",
      "         0.20661157, 0.20661157],\n",
      "        ...,\n",
      "        [0.77272725, 0.78099173, 0.7933884 , ..., 0.1446281 ,\n",
      "         0.1446281 , 0.1446281 ],\n",
      "        [0.77272725, 0.7768595 , 0.7892562 , ..., 0.13636364,\n",
      "         0.13636364, 0.13636364],\n",
      "        [0.7644628 , 0.7892562 , 0.78099173, ..., 0.15289256,\n",
      "         0.15289256, 0.15289256]],\n",
      "\n",
      "       [[0.3181818 , 0.40082645, 0.49173555, ..., 0.40082645,\n",
      "         0.3553719 , 0.30991736],\n",
      "        [0.30991736, 0.3966942 , 0.47933885, ..., 0.40495867,\n",
      "         0.37603307, 0.30165288],\n",
      "        [0.26859504, 0.34710744, 0.45454547, ..., 0.3966942 ,\n",
      "         0.37190083, 0.30991736],\n",
      "        ...,\n",
      "        [0.1322314 , 0.09917355, 0.08264463, ..., 0.13636364,\n",
      "         0.14876033, 0.15289256],\n",
      "        [0.11570248, 0.09504132, 0.0785124 , ..., 0.1446281 ,\n",
      "         0.1446281 , 0.1570248 ],\n",
      "        [0.11157025, 0.09090909, 0.0785124 , ..., 0.14049587,\n",
      "         0.14876033, 0.15289256]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.5       , 0.53305787, 0.607438  , ..., 0.28512397,\n",
      "         0.23966943, 0.21487603],\n",
      "        [0.49173555, 0.5413223 , 0.60330576, ..., 0.29752067,\n",
      "         0.20247933, 0.20661157],\n",
      "        [0.46694216, 0.55785125, 0.6198347 , ..., 0.29752067,\n",
      "         0.17768595, 0.18595041],\n",
      "        ...,\n",
      "        [0.03305785, 0.46280992, 0.5289256 , ..., 0.17355372,\n",
      "         0.17355372, 0.1694215 ],\n",
      "        [0.1570248 , 0.5247934 , 0.53305787, ..., 0.16528925,\n",
      "         0.1570248 , 0.18595041],\n",
      "        [0.45454547, 0.5206612 , 0.53305787, ..., 0.17768595,\n",
      "         0.14876033, 0.19008264]],\n",
      "\n",
      "       [[0.21487603, 0.21900827, 0.21900827, ..., 0.71487606,\n",
      "         0.71487606, 0.6942149 ],\n",
      "        [0.20247933, 0.20661157, 0.20661157, ..., 0.7107438 ,\n",
      "         0.7066116 , 0.6942149 ],\n",
      "        [0.2107438 , 0.20661157, 0.20661157, ..., 0.6859504 ,\n",
      "         0.69008267, 0.6942149 ],\n",
      "        ...,\n",
      "        [0.2644628 , 0.25619835, 0.2603306 , ..., 0.5413223 ,\n",
      "         0.57438016, 0.59090906],\n",
      "        [0.26859504, 0.2644628 , 0.26859504, ..., 0.56198347,\n",
      "         0.58264464, 0.59504133],\n",
      "        [0.27272728, 0.26859504, 0.27272728, ..., 0.57438016,\n",
      "         0.59090906, 0.60330576]],\n",
      "\n",
      "       [[0.5165289 , 0.46280992, 0.28099173, ..., 0.5785124 ,\n",
      "         0.5413223 , 0.60330576],\n",
      "        [0.5165289 , 0.45041323, 0.29338843, ..., 0.58264464,\n",
      "         0.553719  , 0.5785124 ],\n",
      "        [0.5165289 , 0.44214877, 0.29338843, ..., 0.59917355,\n",
      "         0.5785124 , 0.54545456],\n",
      "        ...,\n",
      "        [0.39256197, 0.41322315, 0.38842976, ..., 0.33471075,\n",
      "         0.37190083, 0.3966942 ],\n",
      "        [0.39256197, 0.38429752, 0.40495867, ..., 0.3305785 ,\n",
      "         0.35950413, 0.37603307],\n",
      "        [0.3677686 , 0.40495867, 0.3966942 , ..., 0.35950413,\n",
      "         0.3553719 , 0.38429752]]], dtype=float32), 'target': array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
      "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
      "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
      "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
      "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
      "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
      "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
      "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
      "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
      "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
      "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
      "       30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32,\n",
      "       32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35,\n",
      "       35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37,\n",
      "       37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39,\n",
      "       39, 39, 39, 39, 39, 39, 39, 39, 39]), 'DESCR': '.. _olivetti_faces_dataset:\\n\\nThe Olivetti faces dataset\\n--------------------------\\n\\n`This dataset contains a set of face images`_ taken between April 1992 and \\nApril 1994 at AT&T Laboratories Cambridge. The\\n:func:`sklearn.datasets.fetch_olivetti_faces` function is the data\\nfetching / caching function that downloads the data\\narchive from AT&T.\\n\\n.. _This dataset contains a set of face images: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\\n\\nAs described on the original website:\\n\\n    There are ten different images of each of 40 distinct subjects. For some\\n    subjects, the images were taken at different times, varying the lighting,\\n    facial expressions (open / closed eyes, smiling / not smiling) and facial\\n    details (glasses / no glasses). All the images were taken against a dark\\n    homogeneous background with the subjects in an upright, frontal position \\n    (with tolerance for some side movement).\\n\\n**Data Set Characteristics:**\\n\\n    =================   =====================\\n    Classes                                40\\n    Samples total                         400\\n    Dimensionality                       4096\\n    Features            real, between 0 and 1\\n    =================   =====================\\n\\nThe image is quantized to 256 grey levels and stored as unsigned 8-bit \\nintegers; the loader will convert these to floating point values on the \\ninterval [0, 1], which are easier to work with for many algorithms.\\n\\nThe \"target\" for this database is an integer from 0 to 39 indicating the\\nidentity of the person pictured; however, with only 10 examples per class, this\\nrelatively small dataset is more interesting from an unsupervised or\\nsemi-supervised perspective.\\n\\nThe original dataset consisted of 92 x 112, while the version available here\\nconsists of 64x64 images.\\n\\nWhen using these images, please give credit to AT&T Laboratories Cambridge.\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(load_olivetti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9518db",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_picture = load_olivetti.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a8c17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32,\n",
       "       32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39,\n",
       "       39, 39, 39, 39, 39, 39, 39, 39, 39])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_olivetti.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5d0089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _olivetti_faces_dataset:\\n\\nThe Olivetti faces dataset\\n--------------------------\\n\\n`This dataset contains a set of face images`_ taken between April 1992 and \\nApril 1994 at AT&T Laboratories Cambridge. The\\n:func:`sklearn.datasets.fetch_olivetti_faces` function is the data\\nfetching / caching function that downloads the data\\narchive from AT&T.\\n\\n.. _This dataset contains a set of face images: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\\n\\nAs described on the original website:\\n\\n    There are ten different images of each of 40 distinct subjects. For some\\n    subjects, the images were taken at different times, varying the lighting,\\n    facial expressions (open / closed eyes, smiling / not smiling) and facial\\n    details (glasses / no glasses). All the images were taken against a dark\\n    homogeneous background with the subjects in an upright, frontal position \\n    (with tolerance for some side movement).\\n\\n**Data Set Characteristics:**\\n\\n    =================   =====================\\n    Classes                                40\\n    Samples total                         400\\n    Dimensionality                       4096\\n    Features            real, between 0 and 1\\n    =================   =====================\\n\\nThe image is quantized to 256 grey levels and stored as unsigned 8-bit \\nintegers; the loader will convert these to floating point values on the \\ninterval [0, 1], which are easier to work with for many algorithms.\\n\\nThe \"target\" for this database is an integer from 0 to 39 indicating the\\nidentity of the person pictured; however, with only 10 examples per class, this\\nrelatively small dataset is more interesting from an unsupervised or\\nsemi-supervised perspective.\\n\\nThe original dataset consisted of 92 x 112, while the version available here\\nconsists of 64x64 images.\\n\\nWhen using these images, please give credit to AT&T Laboratories Cambridge.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_olivetti.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0caea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "print(first_picture.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80b951ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_olivetti.data\n",
    "target = load_olivetti.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ffc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e13a2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46694216 0.4752066  0.45454547 ... 0.6694215  0.6735537  0.6570248 ]\n",
      " [0.40082645 0.49586776 0.57024795 ... 0.16115703 0.1570248  0.13636364]\n",
      " [0.6322314  0.6570248  0.677686   ... 0.19008264 0.21900827 0.27272728]\n",
      " ...\n",
      " [0.40082645 0.5165289  0.56198347 ... 0.11983471 0.16115703 0.15289256]\n",
      " [0.37190083 0.34710744 0.3677686  ... 0.7066116  0.6818182  0.5495868 ]\n",
      " [0.08677686 0.09917355 0.11570248 ... 0.2107438  0.3181818  0.49173555]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(data, target): \n",
    "    data_train= data[train_index]\n",
    "    data_test = data[test_index]\n",
    "    target_train = target[train_index]\n",
    "    target_test = target[test_index]\n",
    "    \n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a564d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = 40\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "target_pred = kmeans.fit_predict(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d5021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scikitlearn_env)",
   "language": "python",
   "name": "scikitlearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
